1. 负责模块

本项目旨在通过搭建和配置Hadoop、HBase、Redis等大数据存储与处理系统，实现对职业病数据的高效存储、管理和查询。项目涵盖了从数据预处理、分布式存储、到前端展示和后端服务对接的完整流程。作为团队的一员，我主要负责以下几个模块的设计与实现：

1. **数据预处理与清洗**
2. **Hadoop完全分布式集群搭建**
3. **HBase完全分布式集群搭建**
4. **Redis完全分布式集群搭建**
5. **数据传输与存储**
6. **网页端功能完善**
7. **前后端服务对接**

**二、各模块详细说明**

**1. 数据预处理与清洗**

**工作内容：**

* 对原始的职业病数据文件进行了整理和清洗，确保数据的一致性和完整性。
* 将数据转换为适合后续处理的格式（如CSV、TSV等），以便于导入分布式存储系统。
* 清洗过程中处理了缺失值、重复数据等问题，确保数据质量。

**完成情况：**

* 成功完成了数据的预处理和清洗工作，生成了干净、结构化的数据文件，为后续的数据存储和分析打下了坚实的基础。

**2. Hadoop完全分布式集群搭建**

**工作内容：**

**图片放置在文末附录处**

* 搭建了一个完全分布式的Hadoop集群，包括NameNode、DataNode、ResourceManager和NodeManager等组件。
* 配置了HDFS（Hadoop Distributed File System）以支持大规模数据的分布式存储。
* 配置了YARN（Yet Another Resource Negotiator）以管理集群资源，支持多任务并发执行。

**完成情况：**

* 成功搭建并配置了Hadoop集群，确保其稳定运行。通过HDFS实现了数据的高效存储和管理，能够支持大规模数据的快速读写操作。

**3. HBase完全分布式集群搭建**

**工作内容：**

* 搭建了一个完全分布式的HBase集群，包括Master节点和RegionServer节点。
* 配置了HBase与Hadoop的集成，确保HBase可以利用HDFS进行数据存储。
* 配置了HBase的高可用性（HA）机制，确保系统的可靠性和容错性。

**完成情况：**

* 成功搭建并配置了HBase集群，确保其与Hadoop无缝集成。通过HBase实现了对职业病数据的高效存储和查询，支持大规模数据的实时访问。

**4. Redis完全分布式集群搭建**

**工作内容：**

* 搭建了一个完全分布式的Redis集群，包含六个结点, ,采用主从复制和哨兵模式（Sentinel）确保高可用性, 集群为三主三从配置。
* 配置了Redis集群的自动故障转移机制，确保在主节点故障时能够快速切换到从节点。
* 使用Redis作为缓存层，加速网页端的查询响应速度。

**完成情况：**

* 成功搭建并配置了Redis集群，确保其稳定运行。通过Redis实现了对热点数据的缓存，显著提升了网页端的查询性能。

**5. 数据传输与存储**

**工作内容：**

* 将清洗后的数据文件传输到Linux虚拟机, 转换为合适的文本格式后，上传至HDFS。
* 使用HBase的importtsv工具将HDFS中的数据导入HBase，确保数据的高效存储和查询。
* 使用DataX工具将HBase中的数据同步到MySQL数据库，确保数据的一致性和持久化。
* 编写了Python脚本，实现了网页与Redis和MySQL的连通对接，确保数据的实时更新和查询。

**完成情况：**

* 成功实现了数据的多级存储和同步，确保数据能够在不同的存储系统之间高效流转。通过DataX工具实现了HBase与MySQL之间的数据同步，确保了数据的一致性和可靠性。

**6. 网页端功能完善**

**工作内容：**

* 修复了网页端的安全漏洞，确保系统的安全性。
* 实现了分页功能，支持用户按需加载数据，提升用户体验。
* 实现了页面跳转功能，方便用户在不同页面之间切换。
* 实现了搜索框功能，支持用户根据编码或名称进行模糊查询，快速定位所需数据。

**完成情况：**

* 成功修复了网页端的安全漏洞，确保系统的安全性。实现了分页、跳转和搜索功能，显著提升了用户的使用体验。

**7. 前后端服务对接**

**工作内容：**

* 使用Python编写了后端服务接口，实现了与Redis和MySQL的连通对接。
* 通过API接口，前端网页可以实时查询和更新数据，确保数据的实时性和准确性。
* 实现了数据的缓存机制，减少了数据库的访问压力，提升了系统的整体性能。

**完成情况：**

* 成功实现了前后端服务的对接，确保了数据的实时更新和查询。通过缓存机制，显著提升了系统的响应速度和性能。

1. 总结

通过本次项目实践，我参与并完成了本次大数据存储与处理实践课程设计的全流程，包括数据预处理、分布式存储系统的搭建、数据传输与同步、以及前后端服务的对接。特别是在Hadoop、HBase、Redis等分布式系统的搭建和配置方面，积累了丰富的经验。同时，通过对网页端功能的完善，提升了系统的安全性和用户体验。